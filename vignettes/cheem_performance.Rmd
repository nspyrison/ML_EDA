---
title: "Cheem performance"
author: "Nicholas Spyrison"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
editor_options:
  chunk_output_type: console
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo       = TRUE, ## code
  include    = TRUE, ## plots
  eval       = TRUE, ## chunk
  message    = FALSE,
  warning    = FALSE,
  error      = FALSE,
  collapse   = TRUE,
  cache      = TRUE,
  cache.lazy = FALSE
)
## Set directory relative to package
knitr::opts_knit$set(root.dir = '..')
```

# Data, DALEX::dragons

## Requirements

```{R}
## Primary work packages
require("DALEX")
require("spinifex")
require("tourr")
require("ggplot2")
## EDA and utility
require("GGally")
require("tictoc")
require("patchwork")
require("plotly")
## Local functions
source("./apps/cheem/trees_of_cheem.r")   ## Cheem functions
source("./apps/cheem/spinifex_ggproto.r") ## New (spinifex) ggproto_* api
## Not run, open local function files
if(F){
  file.edit("./apps/cheem/trees_of_cheem.r")
  file.edit("./apps/cheem/spinifex_ggproto.r")
}
require("microbenchmark")
```

## Data setup

```{r}
raw <- spinifex::PimaIndiansDiabetes_wide
str(raw) ## dat: 392 x 9, clas: diabetes: 2 level factor
dat <- spinifex::scale_sd(raw[, -9])
tgt_var <- clas <- raw$diabetes

## Observations per class
table(clas)


```



# DALEX::predict_parts
```{r}
.p <- ncol(dat)
.rf <- randomForest::randomForest(tgt_var~.,
                                  data = data.frame(tgt_var, dat),
                                  mtry = if(is.discrete(tgt_var)) sqrt(.p) else .p / 3L)
## Explainer of the random forest model
expl <- DALEX::explain(model = .rf,
                       data = dat,
                       y = tgt_var,
                       label = "local attribution of random forest model")

bas_cheem <- basis_cheem(explainer = expl, 
                         new_observation = new_obs)
bas_cheem ## method, print.basis_cheem
plot(bas_cheem) ## method, plot.basis_cheem
```

# treeshap

## Extract local attribution matrix

Create the local attribution for _every_ observation and then reconstituted back into a [n, p] matrix. This is taking way too long, so we'll take a 10% subset, running a RF model 200 times on data with dim [200, 7]. 

```{r}
tictoc::tic("local_attribution_matrix")
capture.output(
  la_mat <- local_attribution_matrix_INSAMP_DOPAR(dat, clas)
  )
tictoc::toc()
```

## Scatterplot matrix of local attribution matrix

```{r}
GGally::ggpairs(as.data.frame(la_mat), mapping = aes(color = clas_sub),
                lower = list(continuous = wrap("points", alpha = 0.3)))
#plotly::ggplotly(gg)
```

We notice clumping near zero, ie many variables are often unimportant for explaining a particular variable. Keep in mind that these are normalized SHAP values, the row norm must be 1.

## Scatterplot matrix of _OLDA_-space of the local attribution matrix

```{r}
bas_olda <- basis_olda(la_mat, clas_sub, d = 5)
colnames(bas_olda) <- paste0("OLD", 1:5)
proj_olda <- la_mat %*% bas_olda
GGally::ggpairs(as.data.frame(proj_olda), mapping = aes(color = clas_sub),
                lower = list(continuous = wrap("points", alpha = 0.3)))
#plotly::ggplotly(gg)
```


# Side-by-side SHAP

Placeholder, ideas:

## When target variable iterates over factor levels

Note this is equivalent to corrupting the class of the held out obs, though I frame it in terms of changing the test variable.

```{r, fig.height=10}
## current y var:  tgt_var <- clas == clas[new_obs]
print(paste0("Above the RF model had dependant variable, y class == ", clas[new_obs], ". Let's see how the SHAP values and their 1d proj change when we iterate thru testing for each of the class levels."))
.lvls <- levels(clas)

sapply(seq_along(.lvls), function(i){
  capture.output(
    bas_cheem <- basis_cheem(data = dat, holdout_rownum = new_obs,
                             target_var = clas == .lvls[i],
                             class = clas, parts_type = "shap", basis_type = NULL)
  )
  g <- plot.cheem_basis(bas_cheem) + 
    ggtitle(paste0("y_var: class == ", .lvls[i]))
  assign(paste0("g", i), g, envir = .GlobalEnv)
})

g1 / g2 /g3 / g4
```

## Observations at center vs edge of a class elipsoid

Another direction to take this would be to texture or rasterize the local rate of change of target var or shap values some how. I think this is trying to aggregate partial dependence values or their first derivative a predicted value, like I would want raster/density of the y var. overlaid on a given projection of x's.

given:
1) X[nxp] * A[pxd] = Y[nxd]
2) f, RF model

Then:
1) make gird on Y,
2) map back to X'.
3) solve SHAP of X', [g, p]
4) raster/heatmap of the change,

Need to interrogate an RF model w.r.t. y-variable, how do you know which classification/species a grid search is?

Alternative:
Consider convex hull points (or all), hold class means as benchmark for comparison, view the norm of the SHAP values away from this point.

```{r, eval=FALSE}
dat  <- scale_sd(tourr::flea[, 1:6])
clas <- tourr::flea$species
bas  <- basis_olda(dat, clas)

proj <- dat %*% bas 
.x_min <- min(proj[, 1])
.x_max <- max(proj[, 1])
.y_min <- min(proj[, 2])
.y_max <- max(proj[, 2])
## Cross join form 100 grid pts
.grid_y <- merge(seq(.x_min, .x_max, length.out = 10),
                 seq(.y_min, .y_max, length.out = 10), by = NULL)
.grid_x <- as.matrix(.grid_y) %*% t(bas)
shap_grid <- matrix(NA, ncol = ncol(.grid_x), nrow = nrow(.grid_x))
sapply(1:nrow(.grid_x), function(i){
  shap_grid[i, ] <<- basis_cheem(data = .grid_x, holdout_rownum = i,
                                 target_var = tgt_var,
                                 class = clas, parts_type = "shap", basis_type = NULL)
})


```

# EDA data space

```{r}
bas_pca4 <- basis_pca(dat, d = 4)
proj_pca4 <- dat %*% bas_pca4
colnames(proj_pca4) <- paste0("PC", 1:4)
GGally::ggpairs(as.data.frame(proj_pca4), 
                mapping = aes(color = clas), 
                lower = list(continuous = wrap("points", alpha = 0.3)))


bas_olda4 <- basis_olda(dat, clas, d = 4)
proj_olda4 <- dat %*% bas_olda4
colnames(proj_olda4) <- paste0("OLDA", 1:4)
GGally::ggpairs(as.data.frame(proj_olda4), 
                mapping = aes(color = clas), 
                lower = list(continuous = wrap("points", alpha = 0.3)))
```

Not a lot of linear separability.


# An aside: DALEX::plot.predict_parts() symmetrically robust?: yes

In short, _yes_.

In the following evaluated R chunk (see code) we permute both the output DALEX::predict_parts columns and that of the input data. Both do not change the print order (though permuting the parts order does destroy the local attribution CI.)

```{r, eval=FALSE}
.parts <- attributes(bas_cheem)$predict_parts
plot(.parts)

## Explore the variable order assyemtry; does var order matter?
colnames(dat) ## 1) plot.predict_parts() doesn't print in variable nor ABC order.
set.seed(1010)
.p <- ncol(dat)
.col_shuffle <- sample(1:.p, .p)
# .parts2 <- .parts[.col_shuffle, ] ## 2) shuffling a plot.predict_parts() obj doesn't change the print order (but has destroys the CI of the values.)
print("Shuffling the predict parts obj, obscurses the CI of the local attribution of the shap values, but not the order displayed. what if we shuffle the variables right out of the gate?")

## Setup dat2, with shuffled columns:
dat2 <- dat[, .col_shuffle]
bas_cheem2 <- basis_cheem(
  data = dat2,
  holdout_rownum = new_obs,
  target_var = tgt_var,
  class = clas,
  parts_type = "shap",
  basis_type = NULL)
.parts2 <- attributes(bas_cheem2)$predict_parts

require("patchwork")
plot(.parts) + plot(.parts2)
print("Great! robust to both the varaible order both before and after")
```

